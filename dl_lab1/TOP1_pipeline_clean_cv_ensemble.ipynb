{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DL Lab 1: TOP1 Pipeline (Clean Train + Group-aware CV + Ensemble)\n",
        "\n",
        "Этот ноутбук делает полный production-like пайплайн для соревнования:\n",
        "- использует очищенный `train` (`strict/aggressive`) и **не трогает** test-файлы;\n",
        "- делает валидацию с учетом структуры `class + plu`;\n",
        "- обучает несколько архитектур по фолдам;\n",
        "- выбирает модели по OOF-метрикам;\n",
        "- строит weighted-ensemble и готовит submission.\n",
        "\n",
        "## Основной принцип\n",
        "Финальный выбор моделей/весов делается по локальной OOF/CV, а не по случайному росту public leaderboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Перед запуском\n",
        "\n",
        "1. Проверьте пути в `CFG`.\n",
        "2. Убедитесь, что установлены пакеты (`torch`, `timm`, `albumentations`, `scikit-learn`).\n",
        "3. Запускайте обучение сначала на `strict` cleaned train.\n",
        "4. `test`-директорию не меняем, не чистим, не дополняем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Если пакетов нет, запустите в отдельной ячейке (локально или на Kaggle):\n",
        "# !pip install -U torch torchvision timm albumentations scikit-learn pandas numpy pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import timm\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class CFG:\n",
        "    seed: int = 42\n",
        "\n",
        "    # Paths\n",
        "    root: str = '/kaggle/input/dl-lab-1-image-classification'  # Kaggle path пример\n",
        "    local_root: str = '/Users/fedorgracev/Desktop/NeuralNetwork/dl_lab1/unzipped'  # local path пример\n",
        "    use_local_paths: bool = True\n",
        "\n",
        "    # Clean train variants:\n",
        "    # - strict: drop only obvious noise\n",
        "    # - aggressive: additionally excludes quarantine rows\n",
        "    clean_variant: str = 'strict'  # ['strict', 'aggressive', 'raw']\n",
        "\n",
        "    # CV\n",
        "    n_folds: int = 5\n",
        "    fold_seed: int = 42\n",
        "\n",
        "    # Training\n",
        "    num_workers: int = 0\n",
        "    batch_size: int = 48\n",
        "    epochs: int = 14\n",
        "    warmup_epochs: int = 2\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    # Aug\n",
        "    img_size: int = 224\n",
        "    use_mixup: bool = True\n",
        "    mixup_alpha: float = 0.2\n",
        "    mixup_prob: float = 0.3\n",
        "\n",
        "    # Runtime flags\n",
        "    run_training: bool = True\n",
        "    run_inference: bool = False\n",
        "\n",
        "    # Ensemble search\n",
        "    ensemble_trials: int = 5000\n",
        "\n",
        "    # Output\n",
        "    out_dir: str = '/Users/fedorgracev/Desktop/NeuralNetwork/dl_lab1/outputs_top1_mps'\n",
        "\n",
        "    # Model zoo for ensemble\n",
        "    model_configs: Tuple[Dict, ...] = (\n",
        "        {\n",
        "            'alias': 'convnext_small',\n",
        "            'timm_name': 'convnext_small.fb_in22k_ft_in1k',\n",
        "            'img_size': 224,\n",
        "            'drop_rate': 0.2,\n",
        "            'drop_path_rate': 0.2,\n",
        "        },\n",
        "        {\n",
        "            'alias': 'effnetv2_s',\n",
        "            'timm_name': 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
        "            'img_size': 224,\n",
        "            'drop_rate': 0.2,\n",
        "            'drop_path_rate': 0.2,\n",
        "        },\n",
        "        {\n",
        "            'alias': 'resnet50',\n",
        "            'timm_name': 'resnet50.a1_in1k',\n",
        "            'img_size': 224,\n",
        "            'drop_rate': 0.1,\n",
        "            'drop_path_rate': 0.1,\n",
        "        },\n",
        "    )\n",
        "\n",
        "CFG = CFG()\n",
        "\n",
        "# Runtime overrides via env vars (useful for smoke/full runs without editing notebook)\n",
        "CFG.batch_size = int(os.getenv('BATCH_SIZE', CFG.batch_size))\n",
        "CFG.epochs = int(os.getenv('EPOCHS', CFG.epochs))\n",
        "CFG.n_folds = int(os.getenv('N_FOLDS', CFG.n_folds))\n",
        "CFG.num_workers = int(os.getenv('NUM_WORKERS', CFG.num_workers))\n",
        "CFG.ensemble_trials = int(os.getenv('ENSEMBLE_TRIALS', CFG.ensemble_trials))\n",
        "\n",
        "if os.getenv('RUN_TRAINING') is not None:\n",
        "    CFG.run_training = os.getenv('RUN_TRAINING') == '1'\n",
        "\n",
        "if os.getenv('RUN_INFERENCE') is not None:\n",
        "    CFG.run_inference = os.getenv('RUN_INFERENCE') == '1'\n",
        "\n",
        "if os.getenv('CLEAN_VARIANT') is not None:\n",
        "    CFG.clean_variant = os.getenv('CLEAN_VARIANT')\n",
        "\n",
        "max_models = int(os.getenv('MAX_MODELS', '0'))\n",
        "if max_models > 0:\n",
        "    CFG.model_configs = CFG.model_configs[:max_models]\n",
        "\n",
        "print(asdict(CFG))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resolve_paths(cfg: CFG) -> Dict[str, Path]:\n",
        "    base = Path(cfg.local_root if cfg.use_local_paths else cfg.root)\n",
        "\n",
        "    if cfg.clean_variant == 'strict':\n",
        "        train_csv = base / 'cleaning' / 'train_clean_strict.csv'\n",
        "    elif cfg.clean_variant == 'aggressive':\n",
        "        train_csv = base / 'cleaning' / 'train_clean_aggressive.csv'\n",
        "    else:\n",
        "        train_csv = base / 'train.csv'\n",
        "\n",
        "    paths = {\n",
        "        'base': base,\n",
        "        'train_csv': train_csv,\n",
        "        'test_csv': base / 'test.csv',\n",
        "        'sample_submission': base / 'sample_submission.csv',\n",
        "        'train_images_dir': base / 'train' / 'train',\n",
        "        'test_images_dir': base / 'test_images' / 'test_images',\n",
        "        'clean_manifest': base / 'cleaning' / 'train_clean_manifest.csv',\n",
        "    }\n",
        "    return paths\n",
        "\n",
        "paths = resolve_paths(CFG)\n",
        "for k, v in paths.items():\n",
        "    print(f'{k}: {v} | exists={v.exists()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG.seed)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "if not torch.backends.mps.is_available():\n",
        "    raise RuntimeError('MPS is not available in current process. Run notebook outside sandbox / with full system access.')\n",
        "\n",
        "device = torch.device('mps')\n",
        "print('device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_train_df(paths: Dict[str, Path]) -> pd.DataFrame:\n",
        "    df = pd.read_csv(paths['train_csv'])\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    splits = df['image_id'].str.split('/', expand=True)\n",
        "    df['class_name'] = splits[0]\n",
        "    df['plu'] = splits[1]\n",
        "    df['file_name'] = splits[2]\n",
        "\n",
        "    # Existence sanity check\n",
        "    missing = []\n",
        "    for rel in df['image_id'].head(2000):\n",
        "        if not (paths['train_images_dir'] / rel).exists():\n",
        "            missing.append(rel)\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f'Found missing train files, e.g. {missing[:3]}')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_test_df(paths: Dict[str, Path]) -> pd.DataFrame:\n",
        "    df = pd.read_csv(paths['test_csv'])\n",
        "    missing = []\n",
        "    for rel in df['image_id'].head(2000):\n",
        "        if not (paths['test_images_dir'] / rel).exists():\n",
        "            missing.append(rel)\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f'Found missing test files, e.g. {missing[:3]}')\n",
        "    return df\n",
        "\n",
        "train_df = load_train_df(paths)\n",
        "test_df = load_test_df(paths)\n",
        "\n",
        "print('train rows:', len(train_df))\n",
        "print('test rows :', len(test_df))\n",
        "print('classes   :', train_df['label'].nunique())\n",
        "print(train_df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label map and class weights for CrossEntropyLoss\n",
        "label_to_class = (\n",
        "    train_df[['label', 'class_name']]\n",
        "    .drop_duplicates()\n",
        "    .sort_values('label')\n",
        "    .set_index('label')['class_name']\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "label_counts = train_df['label'].value_counts().sort_index()\n",
        "num_classes = len(label_counts)\n",
        "N = len(train_df)\n",
        "\n",
        "# Inverse-frequency style (effective baseline)\n",
        "class_weights = {k: N / (num_classes * v) for k, v in label_counts.to_dict().items()}\n",
        "max_w = max(class_weights.values())\n",
        "class_weights = {k: v / max_w for k, v in class_weights.items()}\n",
        "class_weights_tensor = torch.tensor([class_weights[i] for i in range(num_classes)], dtype=torch.float32)\n",
        "\n",
        "print('label_to_class:', label_to_class)\n",
        "print('class_counts:')\n",
        "print(label_counts)\n",
        "print('class_weights (normalized):', class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Fold strategy\n",
        "\n",
        "Используем стратификацию по `label + plu` (ключ вида `\"11_4314547\"`).\n",
        "Это учитывает идею преподавателя: не только класс, но и подгруппа внутри класса.\n",
        "\n",
        "Дополнительно сохраняем folds на диск для воспроизводимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_folds(df: pd.DataFrame, n_splits: int, seed: int) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['fold'] = -1\n",
        "    df['strat_key'] = df['label'].astype(str) + '_' + df['plu'].astype(str)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    for fold, (_, val_idx) in enumerate(skf.split(df, df['strat_key'])):\n",
        "        df.loc[df.index[val_idx], 'fold'] = fold\n",
        "\n",
        "    assert (df['fold'] >= 0).all()\n",
        "    return df\n",
        "\n",
        "fold_df = make_folds(train_df, CFG.n_folds, CFG.fold_seed)\n",
        "\n",
        "out_dir = Path(CFG.out_dir)\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "folds_path = out_dir / f'folds_{CFG.clean_variant}_{CFG.n_folds}f.csv'\n",
        "fold_df.to_csv(folds_path, index=False)\n",
        "print('saved:', folds_path)\n",
        "\n",
        "print(fold_df.groupby('fold')['label'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_fold_balance(df: pd.DataFrame):\n",
        "    stats = []\n",
        "    for f in sorted(df['fold'].unique()):\n",
        "        d = df[df['fold'] == f]\n",
        "        cls = d['label'].value_counts().sort_index()\n",
        "        stats.append((f, len(d), cls.min(), cls.max(), cls.std()))\n",
        "    balance = pd.DataFrame(stats, columns=['fold', 'n', 'min_cls', 'max_cls', 'std_cls'])\n",
        "    return balance\n",
        "\n",
        "balance_df = check_fold_balance(fold_df)\n",
        "print(balance_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Augmentations\n",
        "\n",
        "Подход:\n",
        "- умеренно сильные геометрические и цветовые искажения;\n",
        "- без слишком агрессивной деформации формы;\n",
        "- `CoarseDropout` для устойчивости к окклюзии;\n",
        "- валидация без stochastic augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_train_tfms(img_size: int) -> A.Compose:\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(size=(img_size, img_size), scale=(0.65, 1.0), ratio=(0.8, 1.25), p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.05,\n",
        "            scale_limit=0.15,\n",
        "            rotate_limit=20,\n",
        "            border_mode=0,\n",
        "            p=0.35,\n",
        "        ),\n",
        "        A.OneOf([\n",
        "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
        "            A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=20, val_shift_limit=20, p=1.0),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "        ], p=0.6),\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
        "            A.GaussNoise(std_range=(0.02, 0.08), p=1.0),\n",
        "            A.ImageCompression(quality_range=(70, 100), p=1.0),\n",
        "        ], p=0.3),\n",
        "        A.CoarseDropout(\n",
        "            num_holes_range=(1, 6),\n",
        "            hole_height_range=(0.04, 0.12),\n",
        "            hole_width_range=(0.04, 0.12),\n",
        "            fill=0,\n",
        "            p=0.2,\n",
        "        ),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def build_valid_tfms(img_size: int) -> A.Compose:\n",
        "    return A.Compose([\n",
        "        A.SmallestMaxSize(max_size=img_size),\n",
        "        A.CenterCrop(height=img_size, width=img_size),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FruitDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        img_dir: Path,\n",
        "        transform: Optional[A.Compose] = None,\n",
        "        is_test: bool = False,\n",
        "    ):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['image_id']\n",
        "        image = np.array(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        if self.is_test:\n",
        "            return image, row['image_id']\n",
        "\n",
        "        label = int(row['label'])\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha <= 0:\n",
        "        return x, y, y, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size, device=x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Model, scheduler, train/eval loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(timm_name: str, num_classes: int, drop_rate: float = 0.2, drop_path_rate: float = 0.2):\n",
        "    # Fallback names for portability\n",
        "    fallback = {\n",
        "        'convnext_small.fb_in22k_ft_in1k': 'convnext_small',\n",
        "        'tf_efficientnetv2_s.in21k_ft_in1k': 'tf_efficientnetv2_s',\n",
        "        'resnet50.a1_in1k': 'resnet50',\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        model = timm.create_model(\n",
        "            timm_name,\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate,\n",
        "        )\n",
        "    except Exception:\n",
        "        model = timm.create_model(\n",
        "            fallback.get(timm_name, timm_name),\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate,\n",
        "        )\n",
        "    return model\n",
        "\n",
        "\n",
        "class WarmupCosineScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, total_epochs, warmup_epochs=2, min_lr=1e-6, last_epoch=-1):\n",
        "        self.total_epochs = total_epochs\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.min_lr = min_lr\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        epoch = self.last_epoch + 1\n",
        "        lrs = []\n",
        "        for base_lr in self.base_lrs:\n",
        "            if epoch <= self.warmup_epochs:\n",
        "                lr = base_lr * epoch / max(1, self.warmup_epochs)\n",
        "            else:\n",
        "                progress = (epoch - self.warmup_epochs) / max(1, self.total_epochs - self.warmup_epochs)\n",
        "                cosine = 0.5 * (1 + math.cos(math.pi * progress))\n",
        "                lr = self.min_lr + (base_lr - self.min_lr) * cosine\n",
        "            lrs.append(lr)\n",
        "        return lrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_logits(model, loader, device, tta: bool = False):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    all_ids = []\n",
        "\n",
        "    for batch in tqdm(loader, leave=False):\n",
        "        x, ids = batch\n",
        "        x = x.to(device)\n",
        "\n",
        "        logits = model(x)\n",
        "\n",
        "        if tta:\n",
        "            x_flip = torch.flip(x, dims=[3])  # horizontal flip\n",
        "            logits_flip = model(x_flip)\n",
        "            logits = 0.5 * (logits + logits_flip)\n",
        "\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_ids.extend(ids)\n",
        "\n",
        "    return torch.cat(all_logits, dim=0).numpy(), all_ids\n",
        "\n",
        "\n",
        "def evaluate_logits(y_true: np.ndarray, logits: np.ndarray) -> Dict[str, float]:\n",
        "    y_pred = logits.argmax(1)\n",
        "    return {\n",
        "        'acc': float(accuracy_score(y_true, y_pred)),\n",
        "        'f1_macro': float(f1_score(y_true, y_pred, average='macro')),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_fold(\n",
        "    fold: int,\n",
        "    model_cfg: Dict,\n",
        "    df: pd.DataFrame,\n",
        "    cfg: CFG,\n",
        "    paths: Dict[str, Path],\n",
        "    class_weights_tensor: torch.Tensor,\n",
        "    device: torch.device,\n",
        "):\n",
        "    train_part = df[df['fold'] != fold].reset_index(drop=True)\n",
        "    val_part = df[df['fold'] == fold].reset_index(drop=True)\n",
        "\n",
        "    img_size = model_cfg['img_size']\n",
        "    train_ds = FruitDataset(train_part, paths['train_images_dir'], transform=build_train_tfms(img_size), is_test=False)\n",
        "    val_ds = FruitDataset(val_part, paths['train_images_dir'], transform=build_valid_tfms(img_size), is_test=False)\n",
        "\n",
        "    # Weighted sampler for imbalance\n",
        "    sample_weights = train_part['label'].map(class_weights).values.astype(np.float32)\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=(device.type == 'cuda'),\n",
        "        drop_last=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=cfg.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=(device.type == 'cuda'),\n",
        "    )\n",
        "\n",
        "    model = create_model(\n",
        "        timm_name=model_cfg['timm_name'],\n",
        "        num_classes=num_classes,\n",
        "        drop_rate=model_cfg.get('drop_rate', 0.2),\n",
        "        drop_path_rate=model_cfg.get('drop_path_rate', 0.2),\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(\n",
        "        weight=class_weights_tensor.to(device),\n",
        "        label_smoothing=cfg.label_smoothing,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    scheduler = WarmupCosineScheduler(\n",
        "        optimizer,\n",
        "        total_epochs=cfg.epochs,\n",
        "        warmup_epochs=cfg.warmup_epochs,\n",
        "        min_lr=cfg.lr * 0.03,\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "    fold_dir = Path(cfg.out_dir) / model_cfg['alias'] / f'fold_{fold}'\n",
        "    fold_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_path = fold_dir / 'best_by_val_loss.pt'\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for x, y in tqdm(train_loader, desc=f'{model_cfg[\"alias\"]} f{fold} e{epoch+1}', leave=False):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            use_mix = cfg.use_mixup and (random.random() < cfg.mixup_prob)\n",
        "\n",
        "            if use_mix:\n",
        "                x, y_a, y_b, lam = mixup_data(x, y, alpha=cfg.mixup_alpha)\n",
        "\n",
        "            with torch.autocast(device_type='cuda', enabled=(device.type == 'cuda')):\n",
        "                logits = model(x)\n",
        "                if use_mix:\n",
        "                    loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "                else:\n",
        "                    loss = criterion(logits, y)\n",
        "\n",
        "            if device.type == 'cuda':\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        all_logits = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "\n",
        "                val_losses.append(loss.item())\n",
        "                all_logits.append(logits.detach().cpu())\n",
        "                all_targets.append(y.detach().cpu())\n",
        "\n",
        "        val_logits = torch.cat(all_logits).numpy()\n",
        "        val_targets = torch.cat(all_targets).numpy()\n",
        "        val_metrics = evaluate_logits(val_targets, val_logits)\n",
        "        val_loss = float(np.mean(val_losses))\n",
        "        tr_loss = float(np.mean(train_losses))\n",
        "\n",
        "        print(\n",
        "            f\"[fold={fold}][{model_cfg['alias']}] epoch={epoch+1}/{cfg.epochs} \"\n",
        "            f\"train_loss={tr_loss:.4f} val_loss={val_loss:.4f} \"\n",
        "            f\"val_acc={val_metrics['acc']:.4f} val_f1m={val_metrics['f1_macro']:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save best by val_loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(\n",
        "                {\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'epoch': epoch + 1,\n",
        "                    'val_loss': val_loss,\n",
        "                    'val_acc': val_metrics['acc'],\n",
        "                    'model_cfg': model_cfg,\n",
        "                    'cfg': asdict(cfg),\n",
        "                },\n",
        "                best_path,\n",
        "            )\n",
        "\n",
        "    del model, train_loader, val_loader, train_ds, val_ds\n",
        "    gc.collect()\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return best_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_cv_for_model(model_cfg: Dict, df: pd.DataFrame, cfg: CFG, paths: Dict[str, Path], device: torch.device):\n",
        "    model_alias = model_cfg['alias']\n",
        "    print(f'\\n=== Running CV for: {model_alias} ===')\n",
        "\n",
        "    oof_logits = np.zeros((len(df), num_classes), dtype=np.float32)\n",
        "    oof_targets = df['label'].values.astype(np.int64)\n",
        "\n",
        "    test_ds = FruitDataset(\n",
        "        test_df,\n",
        "        paths['test_images_dir'],\n",
        "        transform=build_valid_tfms(model_cfg['img_size']),\n",
        "        is_test=True,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=CFG.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=CFG.num_workers,\n",
        "        pin_memory=(device.type == 'cuda'),\n",
        "    )\n",
        "    test_logits_folds = []\n",
        "\n",
        "    for fold in range(cfg.n_folds):\n",
        "        best_path = train_one_fold(\n",
        "            fold=fold,\n",
        "            model_cfg=model_cfg,\n",
        "            df=df,\n",
        "            cfg=cfg,\n",
        "            paths=paths,\n",
        "            class_weights_tensor=class_weights_tensor,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        # Load best checkpoint for fold inference\n",
        "        model = create_model(\n",
        "            timm_name=model_cfg['timm_name'],\n",
        "            num_classes=num_classes,\n",
        "            drop_rate=model_cfg.get('drop_rate', 0.2),\n",
        "            drop_path_rate=model_cfg.get('drop_path_rate', 0.2),\n",
        "        ).to(device)\n",
        "\n",
        "        ckpt = torch.load(best_path, map_location=device)\n",
        "        model.load_state_dict(ckpt['model_state_dict'])\n",
        "        model.eval()\n",
        "\n",
        "        # OOF logits\n",
        "        val_part = df[df['fold'] == fold].reset_index(drop=True)\n",
        "        val_ds = FruitDataset(\n",
        "            val_part,\n",
        "            paths['train_images_dir'],\n",
        "            transform=build_valid_tfms(model_cfg['img_size']),\n",
        "            is_test=False,\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_ds,\n",
        "            batch_size=cfg.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=cfg.num_workers,\n",
        "            pin_memory=(device.type == 'cuda'),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fold_logits = []\n",
        "            for x, y in tqdm(val_loader, desc=f'OOF {model_alias} fold{fold}', leave=False):\n",
        "                x = x.to(device)\n",
        "                logits = model(x)\n",
        "                fold_logits.append(logits.detach().cpu())\n",
        "            fold_logits = torch.cat(fold_logits).numpy()\n",
        "\n",
        "        oof_logits[df['fold'].values == fold] = fold_logits\n",
        "\n",
        "        # Test logits with TTA\n",
        "        fold_test_logits, test_ids = predict_logits(model, test_loader, device, tta=True)\n",
        "        test_logits_folds.append(fold_test_logits)\n",
        "\n",
        "        del model, val_ds, val_loader\n",
        "        gc.collect()\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Aggregate test logits across folds\n",
        "    test_logits = np.mean(np.stack(test_logits_folds, axis=0), axis=0)\n",
        "\n",
        "    # Save artifacts\n",
        "    model_dir = Path(cfg.out_dir) / model_alias\n",
        "    model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    np.save(model_dir / 'oof_logits.npy', oof_logits)\n",
        "    np.save(model_dir / 'oof_targets.npy', oof_targets)\n",
        "    np.save(model_dir / 'test_logits.npy', test_logits)\n",
        "\n",
        "    metrics = evaluate_logits(oof_targets, oof_logits)\n",
        "    print(f\"OOF metrics [{model_alias}] -> acc={metrics['acc']:.5f}, f1_macro={metrics['f1_macro']:.5f}\")\n",
        "\n",
        "    with open(model_dir / 'metrics.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Запуск обучения (много часов)\n",
        "\n",
        "Сначала запустите 1 модель и проверьте, что пайплайн корректен.\n",
        "Потом масштабируйте до нескольких архитектур."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if CFG.run_training:\n",
        "    all_metrics = {}\n",
        "    for mcfg in CFG.model_configs:\n",
        "        metrics = run_cv_for_model(mcfg, fold_df, CFG, paths, device)\n",
        "        all_metrics[mcfg['alias']] = metrics\n",
        "\n",
        "    with open(Path(CFG.out_dir) / 'all_model_oof_metrics.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print('Training done. Metrics:')\n",
        "    print(json.dumps(all_metrics, ensure_ascii=False, indent=2))\n",
        "else:\n",
        "    print('CFG.run_training=False -> skipping training.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Ensemble по OOF (веса ищутся на train OOF)\n",
        "\n",
        "Идея: подбираем веса моделей так, чтобы максимизировать OOF accuracy.\n",
        "Это обычно надежнее, чем выбирать веса по public leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_artifacts(out_dir: Path, model_aliases: List[str]):\n",
        "    oof_logits_list = []\n",
        "    test_logits_list = []\n",
        "\n",
        "    for alias in model_aliases:\n",
        "        model_dir = out_dir / alias\n",
        "        oof_logits = np.load(model_dir / 'oof_logits.npy')\n",
        "        test_logits = np.load(model_dir / 'test_logits.npy')\n",
        "        oof_logits_list.append(oof_logits)\n",
        "        test_logits_list.append(test_logits)\n",
        "\n",
        "    return oof_logits_list, test_logits_list\n",
        "\n",
        "\n",
        "def score_weights(oof_logits_list: List[np.ndarray], y_true: np.ndarray, w: np.ndarray) -> float:\n",
        "    w = w / (w.sum() + 1e-12)\n",
        "    blended = np.zeros_like(oof_logits_list[0])\n",
        "    for wi, lg in zip(w, oof_logits_list):\n",
        "        blended += wi * lg\n",
        "    pred = blended.argmax(1)\n",
        "    return accuracy_score(y_true, pred)\n",
        "\n",
        "\n",
        "def search_best_weights(oof_logits_list: List[np.ndarray], y_true: np.ndarray, trials: int = 5000, seed: int = 42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(oof_logits_list)\n",
        "\n",
        "    # start from uniform\n",
        "    best_w = np.ones(n, dtype=np.float64) / n\n",
        "    best_score = score_weights(oof_logits_list, y_true, best_w)\n",
        "\n",
        "    for _ in tqdm(range(trials), desc='weight search'):\n",
        "        w = rng.dirichlet(np.ones(n))\n",
        "        s = score_weights(oof_logits_list, y_true, w)\n",
        "        if s > best_score:\n",
        "            best_score = s\n",
        "            best_w = w\n",
        "\n",
        "    return best_w, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_aliases = [m['alias'] for m in CFG.model_configs]\n",
        "out_dir = Path(CFG.out_dir)\n",
        "\n",
        "missing = [a for a in model_aliases if not (out_dir / a / 'oof_logits.npy').exists()]\n",
        "if missing:\n",
        "    print('Missing model artifacts:', missing)\n",
        "    print('Train models first, then run ensemble.')\n",
        "else:\n",
        "    oof_logits_list, test_logits_list = load_model_artifacts(out_dir, model_aliases)\n",
        "    y_true = np.load(out_dir / model_aliases[0] / 'oof_targets.npy')\n",
        "\n",
        "    # Individual model scores\n",
        "    print('Individual OOF accuracy:')\n",
        "    for alias, lg in zip(model_aliases, oof_logits_list):\n",
        "        print(alias, accuracy_score(y_true, lg.argmax(1)))\n",
        "\n",
        "    best_w, best_oof = search_best_weights(\n",
        "        oof_logits_list,\n",
        "        y_true,\n",
        "        trials=CFG.ensemble_trials,\n",
        "        seed=CFG.seed,\n",
        "    )\n",
        "\n",
        "    print('Best OOF accuracy:', best_oof)\n",
        "    print('Best weights:')\n",
        "    for a, w in zip(model_aliases, best_w):\n",
        "        print(f'  {a}: {w:.4f}')\n",
        "\n",
        "    # Blend test logits\n",
        "    best_w = best_w / best_w.sum()\n",
        "    test_blend = np.zeros_like(test_logits_list[0])\n",
        "    for w, lg in zip(best_w, test_logits_list):\n",
        "        test_blend += w * lg\n",
        "\n",
        "    test_pred = test_blend.argmax(1)\n",
        "\n",
        "    sub = pd.read_csv(paths['sample_submission'])\n",
        "    sub['label'] = test_pred\n",
        "\n",
        "    sub_path = out_dir / 'submission_ensemble_oof_optimized.csv'\n",
        "    sub.to_csv(sub_path, index=False)\n",
        "    print('Saved submission:', sub_path)\n",
        "\n",
        "    with open(out_dir / 'ensemble_weights.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump({a: float(w) for a, w in zip(model_aliases, best_w)}, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Анти-overfit правила (обязательные)\n",
        "\n",
        "1. Не выбирайте финальный сабмит по одному public score.\n",
        "2. Делайте shortlist по OOF: высокий mean + низкий std между фолдами.\n",
        "3. Submit only top-k кандидатов по OOF (например, 2-3 в день).\n",
        "4. Не меняйте data cleaning и folds в середине серии сравнений.\n",
        "5. Логируйте все эксперименты (`model`, `seed`, `img_size`, `aug`, `loss`, `OOF`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Что улучшать дальше\n",
        "\n",
        "- Stage-2 fine-tune (последние эпохи на большем `img_size`, меньшем LR).\n",
        "- EMA весов модели.\n",
        "- Псевдолейблы только с очень высоким порогом уверенности (и только после сильного OOF baseline).\n",
        "- Дополнительные архитектуры в ансамбль (например, `coatnet`, `beit`, `swin`) после проверки OOF-дельты."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}